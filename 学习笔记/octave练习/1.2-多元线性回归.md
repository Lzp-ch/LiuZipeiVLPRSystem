

### ex1

背景：Suppose you are selling your house and you want to know what a good market price would be. One way to do this is to ﬁrst collect information on recent houses sold and make a model of housing prices. 

#### 载入数据

~~~ octave
data = load('ex1data2.txt');
X = data(:, 1:2);%取第一列，第二列的所有数据
y = data(:, 3);%取第三列的所有数据
m = length(y);
~~~



#### 正则化（Feature Normalization）

发现特征值之间相差量级大，为了使得算法更快收敛，要采用标准化，使得两个特征值都满足

- 成为均值为0、方差1的数据集

正则化公式:

其中$\mu$是平均值，$\sigma$是标准差
$$
z = \frac{x-\mu}{\sigma}
$$


~~~octave
% Scale features and set them to zero mean
fprintf('Normalizing Features ...\n');

[X mu sigma] = featureNormalize(X);
~~~

##### featureNormalize.m

~~~octave
function [X_norm, mu, sigma] = featureNormalize(X)
%FEATURENORMALIZE Normalizes the features in X 
%   FEATURENORMALIZE(X) returns a normalized version of X where
%   the mean value of each feature is 0 and the standard deviation
%   is 1. This is often a good preprocessing step to do when
%   working with learning algorithms.

% You need to set these values correctly
X_norm = X;
mu = zeros(1, size(X, 2));
sigma = zeros(1, size(X, 2));

% ====================== YOUR CODE HERE ======================
% Instructions: First, for each feature dimension, compute the mean
%               of the feature and subtract it from the dataset,
%               storing the mean value in mu. Next, compute the 
%               standard deviation of each feature and divide
%               each feature by it's standard deviation, storing
%               the standard deviation in sigma. 
%
%               Note that X is a matrix where each column is a 
%               feature and each row is an example. You need 
%               to perform the normalization separately for 
%               each feature. 
%
% Hint: You might find the 'mean' and 'std' functions useful.
%       
mu = mean(X); %storing the mean value in mu
sigma = std(X);     %  standard deviation
X_norm  = (X - repmat(mu,size(X,1),1)) ./  repmat(sigma,size(X,1),1);




% ============================================================

end
~~~

##### repmat函数的使用

~~~octave
B = repmat(A,m,n)
B = repmat(A,[m n])
~~~

 将A矩阵看作元素，复制组成m行n列，即将A复制m*n个

 ~~~
>> A = [1,2;3,4]

A =
1 2
3 4

>> B = repmat(A,2,3)

B =
1 2   1 2   1 2
3 4   3 4   3 4

1 2   1 2   1 2
3 4   3 4   3 4
 ~~~

所以

~~~octave
X_norm  = (X - repmat(mu,size(X,1),1)) ./  repmat(sigma,size(X,1),1);
~~~

就是，让所有X都减去平均值后再除以标准差，这里的repmat是为了构造跟X一样维度的相应的矩阵，从而可以进行矩阵之间的运算

#### 给X矩阵增加一列1作为x~0~

~~~octave
X = [ones(m, 1) X];
~~~



#### 代价函数的计算

##### 代价函数

$$
J(\theta) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2
$$

##### 向量化后的式子

$$
J(\theta) = \frac{1}{2m}(X\theta-y)^T(X\theta-y)
$$

##### 在octave中

~~~octave
J = sum((X * theta - y).^2) / (2*m); 
~~~

当然也可以写成带转置的式子，只是这样更方便

#### 梯度下降算法

~~~ octave
function [theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters)
%GRADIENTDESCENTMULTI Performs gradient descent to learn theta
%   theta = GRADIENTDESCENTMULTI(x, y, theta, alpha, num_iters) updates theta by
%   taking num_iters gradient steps with learning rate alpha

% Initialize some useful values
m = length(y); % number of training examples
J_history = zeros(num_iters, 1);

for iter = 1:num_iters

    % ====================== YOUR CODE HERE ======================
    % Instructions: Perform a single gradient step on the parameter vector
    %               theta. 
    %
    % Hint: While debugging, it can be useful to print out the values
    %       of the cost function (computeCostMulti) and gradient here.
    %

	theta = theta - alpha / m * X' * (X * theta - y);
	








    % ============================================================

    % Save the cost J in every iteration    
    J_history(iter) = computeCostMulti(X, y, theta);

end

end
~~~

#### 迭代次数与J的图像

~~~ octave
figure;
plot(1:numel(J_history), J_history, '-b', 'LineWidth', 2);
xlabel('Number of iterations');
ylabel('Cost J');
~~~

#### 数据验证

~~~ octave
price = [1 (([1650 3]-mu) ./ sigma)] * theta ;
~~~



